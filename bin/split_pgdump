#!/usr/bin/env ruby
# vim: set syntax=ruby shiftwidth=2 softtabstop=2 tabstop=8 expandtab
require 'optparse'
require 'fileutils'
require 'strscan'
require 'thread'

$debug = false

class CWorker
  attr_accessor :rules_file, :output_file, :sorter, :rules, :num_workers
  def initialize
    @rules_file = 'split.rules'
    @output_file = 'dump.sql'
    @sorter = `which sort`.chomp
    @rules = []
    @num_workers = 2
    @io_workers = []
    @queue = Queue.new
  end

  def tables_dir
    output_file + '-tables'
  end

  def clear_files
    FileUtils.rm_f output_file
    FileUtils.rm_rf Dir[File.join(tables_dir, '*')]
    FileUtils.mkdir_p tables_dir
  end

  def parse_rules
    if File.exists?(rules_file)
      File.open(rules_file) do |f|
        f.each_line do |line|
          if rule = Rule.parse(line)
            @rules << rule
          end
        end
      end
    else
      puts "NO FILE #{rules_file}"  if $debug
    end
  end

  def find_rule(table)
    @rules.find{|rule| table =~ rule.regex}
  end

  def process_schema_line(out, line)
    if line =~ /^COPY (\w+) \(([^)]+)\) FROM stdin;/
      table_name, columns = $1, $2.split(', ')
      @table = Table.new(tables_dir, @schema, table_name, columns)
      @tables << @table
      puts "Start to write table #{table_name}" if $debug
      @state = :table
    else
      if line =~ /^SET search_path = ([^,]+)/
        @schema = $1
      end
      out.write line
    end
  end

  def process_copy_line(out, line)
    if line =~ /^\\\.[\r\n]/
      @table.flush_all
      @table.copy_lines{|l| out.puts l}
      @table = nil
      @state = :schema
    else
      @table.add_line(line)
    end
  end

  def work
    start_io_workers
    @state = :schema
    @table = nil
    @tables = []
    @schema = 'public'

    File.open(output_file, 'w') do |out|
      STDIN.each_line do |line|
        case @state
        when :schema
          process_schema_line(out, line)
        when :table
          process_copy_line(out, line)
        end
      end
    end

    @tables.each{|table| table.finish_all}
    stop_io_workers
  end

  def start_io_workers
    @num_workers.times do
      @io_workers << Thread.new do
        while (job = @queue.pop) != :stop
          job.call
        end
      end
    end
  end

  def stop_io_workers
    (@num_workers +1).times do
      @queue.push :stop
    end
    @io_workers.each{|w| w.join}
  end

  def add_job(&block)
    if @num_workers > 0
      @queue.push block
    else
      block.call
    end
  end
end

Worker = CWorker.new

class Rule
  class ParseError < StandardError; end

  attr_reader :regex, :split_parts, :sort_keys
  def self.parse(line)
    line = line.sub(%r{(;|#|//).*$},'').strip
    return if line.empty?

    if line =~ /^(\S+)(?:\s+split:(\S+))?(?:\s+sort:((?:(?:[^\s:]+)(?::[MbdfghinRrV]+)?(?:\s+|\s*$))+))?$/
      puts "#$1 split:#$2 sort:#$3" if $debug
      new($1, $2, $3)
    else
      raise ParseError, "Wrong rule line #{line}"
    end
  end

  def initialize(table_regex, split_expr, sort_keys)
    @regex = Regexp.new table_regex
    parse_split_expr(split_expr)
    parse_sort_keys(sort_keys)
  end

  def parse_split_expr(split_expr)
    s = StringScanner.new(split_expr || '')
    parts = []
    while !s.eos?
      if field = s.scan(/\$[^\[%]+/)
        field = field[1..-1]
        part = {:type => :field, :field => field, :actions => []}
        while !s.eos?
          if range = s.scan(/\[[+-]?\d+\.\.\.?[+-]?\d+\]/)
            part[:actions] << {:range => range}
          elsif mod = s.scan(/%\d+/)
            part[:actions] << {:mod => mod[1..-1]}
          else
            break
          end
        end
        parts << part
        if sep = s.scan(/![^$\s#\\]*/)
          if sep > '!'
            parts << {:type => :sep, :sep => sep[1..-1]}
          end
          next
        end
      end
      raise ParseError, "Wrong format of split expr #{split_expr} (rest: #{s.rest})"
    end
    @split_parts = parts
  end

  def parse_sort_keys(sort_keys)
    @sort_keys = (sort_keys || '').scan(/([^\s:]+)(?::([MbdfghinRrV]+))?/).map do |key, flags|
      {:field => key, :flags => flags}
    end
  end
end

class Table
  class NoColumn < StandardError; end
  ONE_FILE_CACHE_SIZE = 128 * 1024
  TOTAL_CACHE_SIZE = 5 * 1024 * 1024
  class OneFile
    attr_reader :file_name, :cache_size
    def initialize(dir, name)
      @file_name = File.join(dir, name)
      @cache_lines = []
      @cache_size = 0
    end

    def add_line(line)
      @cache_lines << line
      @cache_size += line.size
    end

    def flush
      dir = File.dirname(@file_name)
      unless File.directory?(dir)
        FileUtils.mkdir_p(dir)
      end
      File.open(@file_name, 'a') do |f|
        @cache_lines.each{|l| f.write(l)}
      end
      @cache_lines.clear
      @cache_size = 0
    end

    def write_finish
      File.open(@file_name, 'a') do |f|
        f.puts('\\.')
      end
    end

    def sort(sort_line = [])
      args = [Worker.sorter]
      if sort_line && !sort_line.empty?
        args.concat sort_line
      else
        args << '-n'
      end
      args.push '-o', @file_name, @file_name
      puts args.join(' ')  if $debug
      system *args
    end
  end

  attr_reader :name, :columns, :files, :sort_line
  def initialize(dir, schema, name, columns)
    @dir = dir
    @table = name
    @schema = schema
    @columns = columns.map{|c| c.sub(/^"(.+)"$/, '\\1')}
    if @rule = Worker.find_rule(name)
      apply_rule
    else
      @split_args = []
    end
    @files = {}
    @total_cache_size = 0
  end

  def _mod(s, len, mod)
    "%0#{len}d" % (s.to_i / mod * mod)
  end

  def apply_rule
    split_string = ''
    @rule.split_parts.each do |part|
      case part[:type]
      when :sep
        split_string << part[:sep]
      when :field
        i = @columns.find_index(part[:field])
        raise NoColumn, part[:field]  unless i
        field = "values[#{i}]"
        part[:actions].each do |action|
          if action[:mod]
            mod_s = action[:mod]
            mod = mod_s.to_i
            field = "_mod(#{field},#{mod_s.size},#{mod})"
          elsif action[:range]
            field << "#{action[:range]}"
          end
        end
        split_string << "\#{#{field}}"
      end
    end

    eval <<-"EOF"
      def self.file_name(values)
        name = %{#{split_string}}.gsub(/\\.\\.|\\s|\\?|\\*/, '_')
        "\#{table_schema}/\#{name}.dat"
      end
    EOF

    @sort_args = @rule.sort_keys.map do |key|
      i = @columns.find_index(key[:field])
      raise NoColumn, key[:field]  unless i
      i += 1
      "--key=#{i},#{i}#{key[:flags]}"
    end
  end

  def table_schema
    @schema == 'public' ? @table : "#@schema/#@table"
  end

  def file_name(values)
    "#{table_schema}.dat"
  end

  def add_line(line)
    values = line.chomp.split("\t")
    fname = file_name(values)
    one_file = @files[fname] ||= OneFile.new(@dir, fname)
    one_file.add_line(line)
    @total_cache_size += line.size
    if one_file.cache_size > ONE_FILE_CACHE_SIZE
      @total_cache_size -= one_file.cache_size
      one_file.flush
    end
    flush_all if @total_cache_size > TOTAL_CACHE_SIZE
  end

  def flush_all
    if @files.size < 10
      @files.each{|name, one_file| one_file.flush}
    else
      counter = @files.size
      queue = Queue.new
      @files.each do |name, one_file|
        Worker.add_job{
          one_file.flush
          queue.push 1
        }
      end
      while counter > 0
        counter -= queue.pop
      end
    end
    @total_cache_size = 0
  end

  def copy_lines
    if block_given?
      @files.each do |name, one_file|
        yield "\\copy #{@table} (#{@columns.join(', ')}) from #{one_file.file_name}"
      end
    else
      to_enum(:copy_lines)
    end
  end

  def finish_all
    @files.each do |name, one_file|
      Worker.add_job do
        one_file.sort(@sort_args)
        one_file.write_finish
      end
    end
  end
end

opts = OptionParser.new do |opts|
  opts.banner = "\
Usage: pg_dump my_base | split_pgdump [-r RULES_FILE] [-f DUMP_FILE] [-s SORT_BIN] [-d]

split_pgdump intend for producing stable set of small files instead of one
big dump file. Such set is suitable for being source for SCM systems, being
effectivly transmitted using rsync, repacking by 7z and other.

"

  opts.separator("Options:")

  opts.on("-r", "--rules=RULES_FILE", "File with rules on table splitting (default 'split.rules')") do |v|
    Worker.rules_file = v
  end
  opts.on("-f", "--file=FILE", "main file name (default 'dump.sql').",
          "Table content will be storred in FILE-tables directory") do |v|
    Worker.output_file = v
  end
  opts.on("-s", "--sort=SORT_BIN", "sort executable compatible with gnu coreutils sort") do |v|
    Worker.sorter = v
  end
  opts.on("-n", "--workers=NUM", Integer, "number of parallel workers for sorting") do |n|
    Worker.num_workers = n
  end
  opts.on("-d", "--debug", "debug"){|v| $debug = true}
  opts.on_tail("-h", "--help", "this message"){|v| puts opts; exit}

  opts.on_tail("\
Rules file format:
table_regexp  {split:<Split expr>} {sort:<Sort expr>}

<Split expr> examples:
  split:$field_name!
  split:$field_name!_$other_field!
  split:$client_id%00100!-$id%0025000!
  split:$some_field[2..-1]!/$other_field[10..30]%0005!

<Sort expr> is space separated list of fields, optionally with options for
gnu `sort` --key parameters (on my machine they are MbdfghinRrV):
  sort:client_id uid
  sort:client_id:n id:n

Example for redmines wiki_content_versions:

wiki_content_versions split:$page_id%0025!/$id%0000250! sort:page_id:n id:n
")

end.parse!

Worker.parse_rules
Worker.clear_files
Worker.work
